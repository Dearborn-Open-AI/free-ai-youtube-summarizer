{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain youtube-transcript-api llama_index llama_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert youtube url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_url='https://www.youtube.com/watch?v=DcWqzZ3I2cY'\n",
    "\n",
    "#check that youtube url is valid\n",
    "from llama_hub.youtube_transcript import is_youtube_video\n",
    "is_youtube_video(youtube_url) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract youtube transcript "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_hub.youtube_transcript import YoutubeTranscriptReader\n",
    "\n",
    "loader = YoutubeTranscriptReader()\n",
    "documents = loader.load_data(ytlinks=[youtube_url])\n",
    "yt_transcript = documents[0].text\n",
    "\n",
    "print(yt_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save youtube video transcript and metadata\n",
    "\n",
    "import json\n",
    "from dataclasses import asdict\n",
    "\n",
    "extracted_data = [{\n",
    "    \"id\": doc.id_,\n",
    "    \"metadata\": doc.metadata,\n",
    "    \"text\": doc.text\n",
    "} for doc in documents]\n",
    "\n",
    "# Save as JSON\n",
    "with open('transcript.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(extracted_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the open source LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chat_models import ChatOllama\n",
    "\n",
    "#change the open source model as required \n",
    "chat_model = ChatOllama(model=\"mistral\", callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]), verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the transcript from saved json file and construct prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "import json\n",
    "\n",
    "# Load the transcript.json file\n",
    "with open('transcript.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract the text from the first item in the data\n",
    "text_content = data[0]['text']\n",
    "\n",
    "# Strip all new lines in the text content\n",
    "text_content_stripped = text_content.replace('\\n', ' ')\n",
    "\n",
    "# Create a HumanMessage with the extracted text\n",
    "human_message = HumanMessage(content=text_content_stripped)\n",
    "\n",
    "# Create a SystemMessage to summarize the text\n",
    "\n",
    "system_prompt = f\"\"\"Generate a concise summary of the transcript provided below.\"\"\"\n",
    "\n",
    "system_message = SystemMessage(content=system_prompt)\n",
    "\n",
    "# Pass the human_message to the chat_model\n",
    "messages = [system_message, human_message]\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the model to summarize the transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = chat_model(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the content from the AIMessage\n",
    "summary_content = summary.content.replace('.', '.\\n\\n')\n",
    "\n",
    "# Save the content to a txt file\n",
    "with open('summary.txt', 'w') as file:\n",
    "    file.write(summary_content)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
